{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Q40jetW8LnwK_LQYi_rKshDDpefPEVvz",
      "authorship_tag": "ABX9TyM91yQ44nP59Z49eKfFUynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdkdaniel/The-Swahili-Project/blob/main/tokenizer_test_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries**"
      ],
      "metadata": {
        "id": "QzDV50ABjwB5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4XaWPkfjjs09"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data**"
      ],
      "metadata": {
        "id": "ta9Xzho7U887"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/drive/MyDrive/Kiswahili_Dataset/Kiswdata1.txt'\n",
        "data = np.loadtxt(filename)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LOvDRUxVB4X",
        "outputId": "ac65c21b-ea6c-4b06-cf65-978e83c59320"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: loadtxt: Empty input file: \"/content/drive/MyDrive/Kiswahili_Dataset/Kiswdata1.txt\"\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open(\"/content/drive/MyDrive/Kiswahili_Dataset/Kiswdata1.txt\",\"a\")\n",
        "print(file1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kGbxjawVvj0",
        "outputId": "71892902-59d6-4ea1-ba17-f3015a1b73f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.TextIOWrapper name='/content/drive/MyDrive/Kiswahili_Dataset/Kiswdata1.txt' mode='a' encoding='UTF-8'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file2 = open(r\"/content/drive/MyDrive/Kiswahili_Dataset/Kiswdata1.txt\",\"w+\")\n",
        "print(file2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3PfNu_nV5cY",
        "outputId": "a2ce1046-bab6-421e-d396-e9a08eaaded9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.TextIOWrapper name='/content/drive/MyDrive/Kiswahili_Dataset/Kiswdata1.txt' mode='w+' encoding='UTF-8'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenizer**"
      ],
      "metadata": {
        "id": "reCWPeDDWT1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "veH85h36WW0J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm  # for our loading bar\n",
        "\n",
        "text_data = []\n",
        "file_count = 0\n",
        "\n",
        "for sample in tqdm(data):\n",
        "    # remove newline characters from each sample as we need to use exclusively as seperators\n",
        "    sample = sample['text'].replace('\\n', '\\s')\n",
        "    text_data.append(sample)\n",
        "    if len(text_data) == 5_000:\n",
        "        # once we hit the 5K mark, save to file\n",
        "        with open(f'./oscar_it/text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
        "            fp.write('\\n'.join(text_data))\n",
        "        text_data = []\n",
        "        file_count += 1\n",
        "# after saving in 5K chunks, we may have leftover samples, we save those now too\n",
        "with open(f'./oscar_it/text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
        "    fp.write('\\n'.join(text_data))"
      ],
      "metadata": {
        "id": "S5ItJp0uWhQ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}