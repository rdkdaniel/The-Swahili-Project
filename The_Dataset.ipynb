{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPSnKaCeiJX6dKEhSziCJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdkdaniel/The-Swahili-Project/blob/main/The_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Collection**"
      ],
      "metadata": {
        "id": "RIxI5nc8anUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Issue**"
      ],
      "metadata": {
        "id": "yAEZDxGyAzWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r6UDesoahVC"
      },
      "outputs": [],
      "source": [
        "#Scrapping works well with stuctured data, like tables etc.\n",
        "#Also, there is the issue of labelling:\n",
        "#Using myself or someelse may result in bias (interpretation of swahili words or sentences based on given labels)\n",
        "  #Also, this will be tedious and costly (time)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Any other alternative???"
      ],
      "metadata": {
        "id": "Z5Hhf8KJ2cq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Collection Methods**"
      ],
      "metadata": {
        "id": "afuAaiLvBAlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.0 Using Scrapy**"
      ],
      "metadata": {
        "id": "UGi-wVlcA18u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.0.0 Libraries**"
      ],
      "metadata": {
        "id": "1pbWMabSCwCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings for notebook\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "# Show Python version\n",
        "import platform\n",
        "platform.python_version()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WrUN4_W9Cogc",
        "outputId": "c3a2bb74-3d0a-4ce0-e5bb-98088298d377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7.15'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.0.1 More Libraries - Scrapy**"
      ],
      "metadata": {
        "id": "pHTohtU_C-pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Scrapy\n",
        "try:\n",
        "    import scrapy\n",
        "except:\n",
        "    !pip install scrapy\n",
        "    import scrapy\n",
        "from scrapy.crawler import CrawlerProcess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj5WgnlfC3Ou",
        "outputId": "f2331d3f-ee4e-4342-f6dc-8e184f77a4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scrapy\n",
            "  Downloading Scrapy-2.7.0-py2.py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting queuelib>=1.4.2\n",
            "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.3)\n",
            "Collecting w3lib>=1.17.0\n",
            "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting protego>=0.1.15\n",
            "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: lxml>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.9.1)\n",
            "Collecting zope.interface>=5.1.0\n",
            "  Downloading zope.interface-5.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 63.0 MB/s \n",
            "\u001b[?25hCollecting cryptography>=3.3\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 67.0 MB/s \n",
            "\u001b[?25hCollecting service-identity>=18.1.0\n",
            "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting Twisted>=18.9.0\n",
            "  Downloading Twisted-22.8.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 42.3 MB/s \n",
            "\u001b[?25hCollecting itemloaders>=1.0.1\n",
            "  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n",
            "Collecting pyOpenSSL>=21.0.0\n",
            "  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)\n",
            "Collecting itemadapter>=0.1.0\n",
            "  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n",
            "Collecting tldextract\n",
            "  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting PyDispatcher>=2.0.5\n",
            "  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)\n",
            "Collecting parsel>=1.5.0\n",
            "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting cssselect>=0.9.1\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->scrapy) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->scrapy) (2.21)\n",
            "Collecting jmespath>=0.9.5\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
            "Collecting hyperlink>=17.1.1\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting incremental>=21.3.0\n",
            "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (4.1.1)\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->scrapy) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->scrapy) (3.0.9)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (3.8.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (1.24.3)\n",
            "Building wheels for collected packages: PyDispatcher\n",
            "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11958 sha256=1779981940e67a4c5bd658dd23e7fdd2039e042a30460cc71bc78f171860a5c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/d6/6a/de198d890277cde60ca3dbebe7ae592d3b381c7d9bb2455f4d\n",
            "Successfully built PyDispatcher\n",
            "Installing collected packages: w3lib, cssselect, zope.interface, requests-file, parsel, jmespath, itemadapter, incremental, hyperlink, cryptography, constantly, Automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy\n",
            "Successfully installed Automat-22.10.0 PyDispatcher-2.0.6 Twisted-22.8.0 constantly-15.1.0 cryptography-38.0.1 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.1.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.7.0 service-identity-21.1.0 tldextract-3.4.0 w3lib-2.0.1 zope.interface-5.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.0.2 Setting Up the Pipeline**"
      ],
      "metadata": {
        "id": "wYO36aQvDNjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "class JsonWriterPipeline(object):\n",
        "\n",
        "    def open_spider(self, spider):\n",
        "        self.file = open('quoteresult.jl', 'w')\n",
        "\n",
        "    def close_spider(self, spider):\n",
        "        self.file.close()\n",
        "\n",
        "    def process_item(self, item, spider):\n",
        "        line = json.dumps(dict(item)) + \"\\n\"\n",
        "        self.file.write(line)\n",
        "        return item"
      ],
      "metadata": {
        "id": "1PdWFAtEDTS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.0.3 Defining the Spider**"
      ],
      "metadata": {
        "id": "UUg54-DXDncf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "        'https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-3.html',\n",
        "        'https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-2.html',\n",
        "    ]\n",
        "    custom_settings = {\n",
        "        'LOG_LEVEL': logging.WARNING,\n",
        "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
        "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
        "        'FEED_URI': 'quoteresult.json'                        # Used for pipeline 2\n",
        "    }\n",
        "    \n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.quote'):\n",
        "            yield {\n",
        "                'text': quote.css('span.text::text').extract_first(),\n",
        "                'author': quote.css('span small::text').extract_first(),\n",
        "                'tags': quote.css('div.tags a.tag::text').extract(),\n",
        "            }"
      ],
      "metadata": {
        "id": "qT0Ye0CGDrKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.0.4 Starting the Crawler**"
      ],
      "metadata": {
        "id": "kt3SkkteEb_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process = CrawlerProcess({\n",
        "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
        "})\n",
        "\n",
        "process.crawl(QuotesSpider)\n",
        "process.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bJEeLvPEfzM",
        "outputId": "3343f8eb-9e97-4000-e574-c7058196f9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:scrapy.utils.log:Scrapy 2.7.0 started (bot: scrapybot)\n",
            "2022-10-31 02:15:32 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: scrapybot)\n",
            "INFO:scrapy.utils.log:Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-31 02:15:32 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "INFO:scrapy.crawler:Overridden settings:\n",
            "{'LOG_LEVEL': 30,\n",
            " 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
            "2022-10-31 02:15:32 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'LOG_LEVEL': 30,\n",
            " 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
            "/usr/local/lib/python3.7/dist-packages/scrapy/utils/request.py:231: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
            "\n",
            "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
            "\n",
            "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
            "  return cls(crawler)\n",
            "DEBUG:scrapy.utils.log:Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "INFO:scrapy.extensions.telnet:Telnet Password: 4beb45944c5cb054\n",
            "/usr/local/lib/python3.7/dist-packages/scrapy/extensions/feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
            "  exporter = cls(crawler)\n",
            "INFO:scrapy.middleware:Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "INFO:scrapy.middleware:Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "INFO:scrapy.middleware:Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "INFO:scrapy.middleware:Enabled item pipelines:\n",
            "['__main__.JsonWriterPipeline']\n",
            "INFO:scrapy.core.engine:Spider opened\n",
            "INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "INFO:scrapy.extensions.telnet:Telnet console listening on 127.0.0.1:6023\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Deferred at 0x7fceb4294c50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-2.html> (referer: None)\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-3.html> (referer: None)\n",
            "INFO:scrapy.core.engine:Closing spider (finished)\n",
            "INFO:scrapy.statscollectors:Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 576,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 383968,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'elapsed_time_seconds': 1.785463,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 10, 31, 2, 15, 34, 843849),\n",
            " 'httpcompression/response_bytes': 2436574,\n",
            " 'httpcompression/response_count': 2,\n",
            " 'memusage/max': 139415552,\n",
            " 'memusage/startup': 139415552,\n",
            " 'response_received_count': 2,\n",
            " 'scheduler/dequeued': 2,\n",
            " 'scheduler/dequeued/memory': 2,\n",
            " 'scheduler/enqueued': 2,\n",
            " 'scheduler/enqueued/memory': 2,\n",
            " 'start_time': datetime.datetime(2022, 10, 31, 2, 15, 33, 58386)}\n",
            "INFO:scrapy.core.engine:Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.0.5 Checking the Files**"
      ],
      "metadata": {
        "id": "VfNebh_TEso5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ll quoteresult.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uobonEnfEvdr",
        "outputId": "7d6bbed2-898f-4e56-e0cb-11ec0924163f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root 0 Oct 31 02:15 quoteresult.jl\n",
            "-rw-r--r-- 1 root 0 Oct 31 02:15 quoteresult.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 2 quoteresult.jl"
      ],
      "metadata": {
        "id": "dhZ6tWL0E1Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 2 quoteresult.json"
      ],
      "metadata": {
        "id": "OY8k4GlTE4ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.0.6 Turning them to Dataframes**"
      ],
      "metadata": {
        "id": "zjuBIlzpE99U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaAAcIRFFD2V",
        "outputId": "a0ebbfcd-9f40-48b1-e92b-4e04247b10c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_json('quoteresult.json', lines=True, orient='records')"
      ],
      "metadata": {
        "id": "r22z5Qkf0_gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "A5Mm104c1eoC",
        "outputId": "42acc6d8-f404-4629-b072-a1789a4d8e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-479dc8ac-74bf-45d5-9709-c50bf95ddf07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-479dc8ac-74bf-45d5-9709-c50bf95ddf07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-479dc8ac-74bf-45d5-9709-c50bf95ddf07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-479dc8ac-74bf-45d5-9709-c50bf95ddf07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.0 Scrapy 2.0**"
      ],
      "metadata": {
        "id": "R5W1bbCfGA0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.0.0 Libraries**"
      ],
      "metadata": {
        "id": "3z-cplTtGF3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scrapy\n",
        "!pip install crochet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68tLb8DcIY3s",
        "outputId": "37abc289-cb86-4866-9c19-bdbdeb69bfcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.0.6)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.2.1)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.7/dist-packages (from scrapy) (38.0.1)\n",
            "Requirement already satisfied: lxml>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.9.1)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (2.0.1)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.1.0)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from scrapy) (21.3)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (22.1.0)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (5.5.0)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (from scrapy) (3.4.0)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (0.7.0)\n",
            "Requirement already satisfied: Twisted>=18.9.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (22.8.0)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.6.2)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (1.6.0)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from scrapy) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->scrapy) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->scrapy) (2.21)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.7/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (20.2.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (4.1.1)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->scrapy) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->scrapy) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (2.23.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (3.8.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (1.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2022.9.24)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting crochet\n",
            "  Downloading crochet-2.0.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from crochet) (1.14.1)\n",
            "Requirement already satisfied: Twisted>=16.0 in /usr/local/lib/python3.7/dist-packages (from crochet) (22.8.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (15.1.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (22.1.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (20.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (4.1.1)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (21.0.0)\n",
            "Requirement already satisfied: zope.interface>=4.4.2 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (5.5.0)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=16.0->crochet) (22.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Automat>=0.8.0->Twisted>=16.0->crochet) (1.15.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=16.0->crochet) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface>=4.4.2->Twisted>=16.0->crochet) (57.4.0)\n",
            "Installing collected packages: crochet\n",
            "Successfully installed crochet-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.0.1 Scrapping the Webpage**"
      ],
      "metadata": {
        "id": "FHxTcsSxIrCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scrape webpage\n",
        "import scrapy\n",
        "from scrapy.crawler import CrawlerRunner\n",
        "# text cleaning\n",
        "import re\n",
        "# Reactor restart\n",
        "from crochet import setup, wait_for\n",
        "setup()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI0RC_eWI2ZT",
        "outputId": "b5a5f4c7-d4b8-4751-b147-b90e466a0541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread CrochetReactor:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/crochet/_eventloop.py\", line 372, in <lambda>\n",
            "    target=lambda: self._reactor.run(installSignalHandlers=False),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\", line 1317, in run\n",
            "    self.startRunning(installSignalHandlers=installSignalHandlers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\", line 1299, in startRunning\n",
            "    ReactorBase.startRunning(cast(ReactorBase, self))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\", line 843, in startRunning\n",
            "    raise error.ReactorNotRestartable()\n",
            "twisted.internet.error.ReactorNotRestartable\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QuotesToCsv(scrapy.Spider):\n",
        "    \"\"\"scrape first line of  quotes from `wikiquote` by \n",
        "    Maynard James Keenan and save to json file\"\"\"\n",
        "    name = \"MJKQuotesToCsv\"\n",
        "    start_urls = [\n",
        "        'https://en.wikiquote.org/wiki/Swahili_proverbs',\n",
        "    ]\n",
        "    custom_settings = {\n",
        "        'ITEM_PIPELINES': {\n",
        "            '__main__.ExtractFirstLine': 1\n",
        "        },\n",
        "        'FEEDS': {\n",
        "            'quotes.csv': {\n",
        "                'format': 'csv',\n",
        "                'overwrite': True\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    def parse(self, response):\n",
        "        \"\"\"parse data from urls\"\"\"\n",
        "        for quote in response.css('div.mw-parser-output > ul > li'):\n",
        "            yield {'quote': quote.extract()}\n",
        "\n",
        "\n",
        "class ExtractFirstLine(object):\n",
        "    def process_item(self, item, spider):\n",
        "        \"\"\"text processing\"\"\"\n",
        "        lines = dict(item)[\"quote\"].splitlines()\n",
        "        first_line = self.__remove_html_tags__(lines[0])\n",
        "\n",
        "        return {'quote': first_line}\n",
        "\n",
        "    def __remove_html_tags__(self, text):\n",
        "        \"\"\"remove html tags from string\"\"\"\n",
        "        html_tags = re.compile('<.*?>')\n",
        "        return re.sub(html_tags, '', text)\n",
        "\n",
        "@wait_for(10)\n",
        "def run_spider():\n",
        "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
        "    crawler = CrawlerRunner()\n",
        "    d = crawler.crawl(QuotesToCsv)\n",
        "    return d"
      ],
      "metadata": {
        "id": "wUl5CgaDIvAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.0.2 Initializing the Crawler**"
      ],
      "metadata": {
        "id": "GUKEWh_aJI-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process = CrawlerProcess()\n",
        "process.crawl(QuotesToCsv)\n",
        "process.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xND6O5Q1JNjB",
        "outputId": "03480968-d07e-421c-aad9-49ec53523b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:scrapy.utils.log:Scrapy 2.7.0 started (bot: scrapybot)\n",
            "2022-10-27 11:14:37 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: scrapybot)\n",
            "INFO:scrapy.utils.log:Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-27 11:14:37 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "INFO:scrapy.crawler:Overridden settings:\n",
            "{}\n",
            "2022-10-27 11:14:37 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "DEBUG:scrapy.utils.log:Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-10-27 11:14:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "INFO:scrapy.extensions.telnet:Telnet Password: 6bd76e2fdcc7e72e\n",
            "2022-10-27 11:14:37 [scrapy.extensions.telnet] INFO: Telnet Password: 6bd76e2fdcc7e72e\n",
            "INFO:scrapy.middleware:Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-10-27 11:14:37 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "INFO:scrapy.middleware:Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-27 11:14:37 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "INFO:scrapy.middleware:Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-27 11:14:37 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "INFO:scrapy.middleware:Enabled item pipelines:\n",
            "['__main__.ExtractFirstLine']\n",
            "2022-10-27 11:14:37 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "['__main__.ExtractFirstLine']\n",
            "INFO:scrapy.core.engine:Spider opened\n",
            "2022-10-27 11:14:37 [scrapy.core.engine] INFO: Spider opened\n",
            "INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-10-27 11:14:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "INFO:scrapy.extensions.telnet:Telnet console listening on 127.0.0.1:6027\n",
            "2022-10-27 11:14:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6027\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Deferred at 0x7ff11c686550>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "error",
          "ename": "ReactorNotRestartable",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReactorNotRestartable\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-bb1bbfd6b7c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrawlerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuotesToCsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, stop_after_crawl, install_signal_handlers)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjustPoolsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'REACTOR_THREADPOOL_MAXSIZE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddSystemEventTrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shutdown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_graceful_stop_reactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \"\"\"\n\u001b[1;32m   1298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_installSignalHandlers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m         \u001b[0mReactorBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReactorBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reallyStartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorAlreadyRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_startedBefore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorNotRestartable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReactorNotRestartable\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.0 Scrapy 3.0**"
      ],
      "metadata": {
        "id": "dea6VxDKJ4ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.0.0 Libraries**"
      ],
      "metadata": {
        "id": "9KDTB6Z5J7lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess"
      ],
      "metadata": {
        "id": "Ey3T4yHCKvSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.0.1 The Spider**"
      ],
      "metadata": {
        "id": "W122p7SJJ7w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MarilynMansonQuotes(scrapy.Spider):\n",
        "    name = \"MarilynMansonQuotes\"\n",
        "    start_urls = [\n",
        "        'https://en.wikiquote.org/wiki/Swahili_proverbs',\n",
        "    ]\n",
        "    \n",
        "    def parse(self, response):\n",
        "        for quote in response.css('div.mw-parser-output > ul > li'):\n",
        "            yield {'quote': quote.extract()}\n",
        "\n",
        "process = CrawlerProcess()\n",
        "process.crawl(MarilynMansonQuotes)\n",
        "process.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ec3M7H8OK3Fw",
        "outputId": "31c69981-88b7-443e-e730-fd5ed3027ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:scrapy.utils.log:Scrapy 2.7.0 started (bot: scrapybot)\n",
            "2022-10-27 11:22:47 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: scrapybot)\n",
            "INFO:scrapy.utils.log:Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-27 11:22:47 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "INFO:scrapy.crawler:Overridden settings:\n",
            "{}\n",
            "2022-10-27 11:22:47 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "DEBUG:scrapy.utils.log:Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-10-27 11:22:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "INFO:scrapy.extensions.telnet:Telnet Password: c12241e290a9f724\n",
            "2022-10-27 11:22:47 [scrapy.extensions.telnet] INFO: Telnet Password: c12241e290a9f724\n",
            "INFO:scrapy.middleware:Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-10-27 11:22:47 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "INFO:scrapy.middleware:Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-27 11:22:47 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "INFO:scrapy.middleware:Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-27 11:22:47 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "INFO:scrapy.middleware:Enabled item pipelines:\n",
            "[]\n",
            "2022-10-27 11:22:47 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "INFO:scrapy.core.engine:Spider opened\n",
            "2022-10-27 11:22:47 [scrapy.core.engine] INFO: Spider opened\n",
            "INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-10-27 11:22:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "INFO:scrapy.extensions.telnet:Telnet console listening on 127.0.0.1:6028\n",
            "2022-10-27 11:22:47 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6028\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Deferred at 0x7ff11c63e250>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "error",
          "ename": "ReactorNotRestartable",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReactorNotRestartable\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-6b109c90aae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrawlerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarilynMansonQuotes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, stop_after_crawl, install_signal_handlers)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjustPoolsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'REACTOR_THREADPOOL_MAXSIZE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddSystemEventTrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shutdown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mreactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_graceful_stop_reactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self, installSignalHandlers)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \"\"\"\n\u001b[1;32m   1298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_installSignalHandlers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstallSignalHandlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m         \u001b[0mReactorBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReactorBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reallyStartRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twisted/internet/base.py\u001b[0m in \u001b[0;36mstartRunning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorAlreadyRunning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_startedBefore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReactorNotRestartable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReactorNotRestartable\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.0.2 Processing pipeline**"
      ],
      "metadata": {
        "id": "RfFqwC3VLqy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class ExtractFirstLine(object):\n",
        "def process_item(self, item, spider):\n",
        "        lines = dict(item)[\"quote\"].splitlines()\n",
        "        first_line = self.__remove_html_tags__(lines[0])\n",
        "        return {'quote': first_line}\n",
        "def __remove_html_tags__(self, text):\n",
        "        html_tags = re.compile('<.*?>')\n",
        "        return re.sub(html_tags, '', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "lou7JIUMLtB6",
        "outputId": "4a627a88-5b5b-4bd2-ed66-1aba73c7feff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-9b0de8e00501>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    def process_item(self, item, spider):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.mikulskibartosz.name/how-to-scrape-a-single-web-page-using-scrapy-in-jupyter-notebook/"
      ],
      "metadata": {
        "id": "zIccyxc2MDsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.0 Scrapy 4.0**"
      ],
      "metadata": {
        "id": "31y21JHv3eHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.0.0 Libraries**"
      ],
      "metadata": {
        "id": "go7jvDOW3lQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to: https://docs.scrapy.org/en/latest/intro/tutorial.html\n",
        "# install scrapy\n",
        "!pip install Scrapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKujOQj_3tNu",
        "outputId": "e87136a0-81be-4575-bdda-5af832a9c424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Scrapy\n",
            "  Downloading Scrapy-2.7.0-py2.py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=21.0.0\n",
            "  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting w3lib>=1.17.0\n",
            "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting Twisted>=18.9.0\n",
            "  Downloading Twisted-22.8.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 49.2 MB/s \n",
            "\u001b[?25hCollecting cryptography>=3.3\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.0 MB/s \n",
            "\u001b[?25hCollecting queuelib>=1.4.2\n",
            "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting itemloaders>=1.0.1\n",
            "  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n",
            "Collecting itemadapter>=0.1.0\n",
            "  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n",
            "Collecting cssselect>=0.9.1\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting parsel>=1.5.0\n",
            "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Scrapy) (57.4.0)\n",
            "Collecting tldextract\n",
            "  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting PyDispatcher>=2.0.5\n",
            "  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from Scrapy) (21.3)\n",
            "Collecting protego>=0.1.15\n",
            "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting service-identity>=18.1.0\n",
            "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting zope.interface>=5.1.0\n",
            "  Downloading zope.interface-5.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from Scrapy) (4.9.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->Scrapy) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->Scrapy) (2.21)\n",
            "Collecting jmespath>=0.9.5\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel>=1.5.0->Scrapy) (1.15.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->Scrapy) (22.1.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->Scrapy) (0.2.8)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->Scrapy) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->Scrapy) (4.1.1)\n",
            "Collecting incremental>=21.3.0\n",
            "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting hyperlink>=17.1.1\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->Scrapy) (2.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->Scrapy) (3.0.9)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract->Scrapy) (2.23.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->Scrapy) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->Scrapy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->Scrapy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->Scrapy) (2022.9.24)\n",
            "Building wheels for collected packages: PyDispatcher\n",
            "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11958 sha256=fb2d56eef65753cfa83231f0e9e89ee028b6a45b95f5d38b851ac97151355ece\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/d6/6a/de198d890277cde60ca3dbebe7ae592d3b381c7d9bb2455f4d\n",
            "Successfully built PyDispatcher\n",
            "Installing collected packages: w3lib, cssselect, zope.interface, requests-file, parsel, jmespath, itemadapter, incremental, hyperlink, cryptography, constantly, Automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, Scrapy\n",
            "Successfully installed Automat-22.10.0 PyDispatcher-2.0.6 Scrapy-2.7.0 Twisted-22.8.0 constantly-15.1.0 cryptography-38.0.1 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.1.0 queuelib-1.6.2 requests-file-1.5.1 service-identity-21.1.0 tldextract-3.4.0 w3lib-2.0.1 zope.interface-5.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.0.1 Others**"
      ],
      "metadata": {
        "id": "SiPcZ2qn3yvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create files for learning\n",
        "!scrapy startproject firstproject"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQcrRiOL31up",
        "outputId": "28f0cb31-42d9-42e8-e0bf-a093577fc7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Scrapy project 'firstproject', using template directory '/usr/local/lib/python3.7/dist-packages/scrapy/templates/project', created in:\n",
            "    /content/firstproject\n",
            "\n",
            "You can start your first spider with:\n",
            "    cd firstproject\n",
            "    scrapy genspider example example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the current working directory\n",
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4LBzZ7_633wQ",
        "outputId": "73555302-3b43-43d8-ea3b-74b60319e204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change working directories\n",
        "os.chdir('/content/firstproject/firstproject/spiders')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tTHaVR1z379r",
        "outputId": "0109e533-13a8-4d46-ecbd-583a560a2361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/firstproject/firstproject/spiders'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create quotes_spider.py and save it under the firstproject/firstproject/spiders directory\n",
        "%%writefile -a quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://quotes.toscrape.com/page/1/',\n",
        "            'https://quotes.toscrape.com/page/2/',\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        page = response.url.split(\"/\")[-2]\n",
        "        filename = f'quotes-{page}.html'\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.body)\n",
        "        self.log(f'Saved file {filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLbjOHWk39Y0",
        "outputId": "cefa3e2e-705d-40b6-f75f-3cf1759b4ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing quotes_spider.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy crawl quotes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEKJmxFS4FFh",
        "outputId": "8a525ed8-e9eb-43b0-d6fe-4146931058fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-31 02:30:40 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: firstproject)\n",
            "2022-10-31 02:30:40 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-31 02:30:40 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'firstproject',\n",
            " 'NEWSPIDER_MODULE': 'firstproject.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['firstproject.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2022-10-31 02:30:40 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2022-10-31 02:30:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2022-10-31 02:30:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2022-10-31 02:30:40 [scrapy.extensions.telnet] INFO: Telnet Password: 9da0cc3af76d6f19\n",
            "2022-10-31 02:30:40 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-10-31 02:30:40 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-31 02:30:40 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-31 02:30:40 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-10-31 02:30:40 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-10-31 02:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-10-31 02:30:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-10-31 02:30:41 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)\n",
            "2022-10-31 02:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/1/> (referer: None)\n",
            "2022-10-31 02:30:41 [quotes] DEBUG: Saved file quotes-1.html\n",
            "2022-10-31 02:30:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com/page/2/> (referer: None)\n",
            "2022-10-31 02:30:42 [quotes] DEBUG: Saved file quotes-2.html\n",
            "2022-10-31 02:30:42 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-10-31 02:30:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 681,\n",
            " 'downloader/request_count': 3,\n",
            " 'downloader/request_method_count/GET': 3,\n",
            " 'downloader/response_bytes': 25579,\n",
            " 'downloader/response_count': 3,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'downloader/response_status_count/404': 1,\n",
            " 'elapsed_time_seconds': 1.657398,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 10, 31, 2, 30, 42, 12166),\n",
            " 'log_count/DEBUG': 8,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 154394624,\n",
            " 'memusage/startup': 154394624,\n",
            " 'response_received_count': 3,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/404': 1,\n",
            " 'scheduler/dequeued': 2,\n",
            " 'scheduler/dequeued/memory': 2,\n",
            " 'scheduler/enqueued': 2,\n",
            " 'scheduler/enqueued/memory': 2,\n",
            " 'start_time': datetime.datetime(2022, 10, 31, 2, 30, 40, 354768)}\n",
            "2022-10-31 02:30:42 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy shell 'https://quotes.toscrape.com'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SBtluDh4Kql",
        "outputId": "145d5b0d-41a5-4a37-d610-aeb8211be3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-31 02:30:57 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: firstproject)\n",
            "2022-10-31 02:30:57 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-31 02:30:57 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'firstproject',\n",
            " 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
            " 'LOGSTATS_INTERVAL': 0,\n",
            " 'NEWSPIDER_MODULE': 'firstproject.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['firstproject.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2022-10-31 02:30:57 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2022-10-31 02:30:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2022-10-31 02:30:57 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2022-10-31 02:30:57 [scrapy.extensions.telnet] INFO: Telnet Password: a9283b716b23ee72\n",
            "2022-10-31 02:30:57 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage']\n",
            "2022-10-31 02:30:57 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-31 02:30:57 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-31 02:30:57 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-10-31 02:30:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-10-31 02:30:57 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-10-31 02:30:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://quotes.toscrape.com/robots.txt> (referer: None)\n",
            "2022-10-31 02:30:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://quotes.toscrape.com> (referer: None)\n",
            "[s] Available Scrapy objects:\n",
            "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
            "[s]   crawler    <scrapy.crawler.Crawler object at 0x7fd70193e390>\n",
            "[s]   item       {}\n",
            "[s]   request    <GET https://quotes.toscrape.com>\n",
            "[s]   response   <200 https://quotes.toscrape.com>\n",
            "[s]   settings   <scrapy.settings.Settings object at 0x7fd6fbac2450>\n",
            "[s]   spider     <DefaultSpider 'default' at 0x7fd6fb2e5e10>\n",
            "[s] Useful shortcuts:\n",
            "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
            "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
            "[s]   shelp()           Shell help (print this help)\n",
            "[s]   view(response)    View response in a browser\n",
            "\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[8D\u001b[J\u001b[0m\u001b[?7h\u001b[?2004l\u001b[?1lWARNING: your terminal doesn't support cursor position requests (CPR).\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\n",
            "\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[0m\u001b[?7h\u001b[0;38;5;88mOut[\u001b[0;91;1m3\u001b[0;38;5;88m]: \u001b[0m\u001b[0m'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'\n",
            "\n",
            "\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.0 Scrapy 5.0**"
      ],
      "metadata": {
        "id": "uwaC5qETVuuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.1 Libraries loaded above**"
      ],
      "metadata": {
        "id": "jzOdFO_HV2SM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.2 Others**"
      ],
      "metadata": {
        "id": "jTFkhaD_V67Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create files for learning\n",
        "!scrapy startproject firstproject"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tsdchzHXwb5",
        "outputId": "01a99618-1bb5-47f1-c038-55621b0464e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Scrapy project 'firstproject', using template directory '/usr/local/lib/python3.7/dist-packages/scrapy/templates/project', created in:\n",
            "    /content/firstproject\n",
            "\n",
            "You can start your first spider with:\n",
            "    cd firstproject\n",
            "    scrapy genspider example example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the current working directory\n",
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3KiDIJUiX1rt",
        "outputId": "0ac9014b-3bf8-4f9c-ec64-c71998d5e024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change working directories\n",
        "os.chdir('/content/firstproject/firstproject/spiders')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GCCRGjSUX6Uh",
        "outputId": "f2305c56-102c-40f1-fe36-7b4e5067444e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/firstproject/firstproject/spiders'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create quotes_spider.py and save it under the firstproject/firstproject/spiders directory\n",
        "%%writefile -a quotes_spider.py\n",
        "import scrapy\n",
        "\n",
        "class QuotesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "\n",
        "    def start_requests(self):\n",
        "        urls = [\n",
        "            'https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-3.html',\n",
        "            'https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-2.html',\n",
        "        ]\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        page = response.url.split(\"/\")[-2]\n",
        "        filename = f'quotes-{page}.html'\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.body)\n",
        "        self.log(f'Saved file {filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdPiiO5gX8LP",
        "outputId": "f034902a-d863-403f-8fe9-4ef92c39dfdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing quotes_spider.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy crawl quotes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSVdZZqfYHyY",
        "outputId": "ead17cdc-1fb8-4003-f729-380db3ddc9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-31 04:50:51 [scrapy.utils.log] INFO: Scrapy 2.7.0 started (bot: firstproject)\n",
            "2022-10-31 04:50:51 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.2.0, parsel 1.6.0, w3lib 2.0.1, Twisted 22.8.0, Python 3.7.15 (default, Oct 12 2022, 19:14:55) - [GCC 7.5.0], pyOpenSSL 22.1.0 (OpenSSL 3.0.5 5 Jul 2022), cryptography 38.0.1, Platform Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-10-31 04:50:51 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'BOT_NAME': 'firstproject',\n",
            " 'NEWSPIDER_MODULE': 'firstproject.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'ROBOTSTXT_OBEY': True,\n",
            " 'SPIDER_MODULES': ['firstproject.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2022-10-31 04:50:51 [asyncio] DEBUG: Using selector: EpollSelector\n",
            "2022-10-31 04:50:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor\n",
            "2022-10-31 04:50:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop\n",
            "2022-10-31 04:50:52 [scrapy.extensions.telnet] INFO: Telnet Password: ea3f39a82e336510\n",
            "2022-10-31 04:50:52 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-10-31 04:50:52 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-10-31 04:50:52 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-10-31 04:50:52 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-10-31 04:50:52 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-10-31 04:50:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-10-31 04:50:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-10-31 04:50:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.advance-africa.com/robots.txt> (referer: None)\n",
            "2022-10-31 04:50:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-3.html> (referer: None)\n",
            "2022-10-31 04:50:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-2.html> (referer: None)\n",
            "2022-10-31 04:50:52 [quotes] DEBUG: Saved file quotes-www.advance-africa.com.html\n",
            "2022-10-31 04:50:52 [quotes] DEBUG: Saved file quotes-www.advance-africa.com.html\n",
            "2022-10-31 04:50:52 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-10-31 04:50:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 776,\n",
            " 'downloader/request_count': 3,\n",
            " 'downloader/request_method_count/GET': 3,\n",
            " 'downloader/response_bytes': 384673,\n",
            " 'downloader/response_count': 3,\n",
            " 'downloader/response_status_count/200': 3,\n",
            " 'elapsed_time_seconds': 0.558393,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 10, 31, 4, 50, 52, 774149),\n",
            " 'httpcompression/response_bytes': 2438328,\n",
            " 'httpcompression/response_count': 3,\n",
            " 'log_count/DEBUG': 8,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 75145216,\n",
            " 'memusage/startup': 75145216,\n",
            " 'response_received_count': 3,\n",
            " 'robotstxt/request_count': 1,\n",
            " 'robotstxt/response_count': 1,\n",
            " 'robotstxt/response_status_count/200': 1,\n",
            " 'scheduler/dequeued': 2,\n",
            " 'scheduler/dequeued/memory': 2,\n",
            " 'scheduler/enqueued': 2,\n",
            " 'scheduler/enqueued/memory': 2,\n",
            " 'start_time': datetime.datetime(2022, 10, 31, 4, 50, 52, 215756)}\n",
            "2022-10-31 04:50:52 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy shell 'https://www.advance-africa.com/KCSE-Past-Papers.htmlquote = response.css(\"div.quote\")[0]'"
      ],
      "metadata": {
        "id": "YiUOenYkYN0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.0 Request HTML**"
      ],
      "metadata": {
        "id": "hRC4rQm8fOsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1 Libraries**"
      ],
      "metadata": {
        "id": "YXkS7BXbfa86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests-html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NqYyzb_f3JN",
        "outputId": "9aec9677-d871-4dd4-d66d-6e2fade8f40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests-html) (2.23.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html) (0.0.1)\n",
            "Collecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "Collecting pyquery\n",
            "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting w3lib\n",
            "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "Collecting urllib3<2.0.0,>=1.25.8\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 56.3 MB/s \n",
            "\u001b[?25hCollecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Collecting websockets<11.0,>=10.0\n",
            "  Downloading websockets-10.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.13.0)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (2022.9.24)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.64.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (4.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html) (4.6.3)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html) (4.9.1)\n",
            "Collecting urllib3<2.0.0,>=1.25.8\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 43.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests-html) (2.10)\n",
            "Building wheels for collected packages: fake-useragent, parse\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=ac4786558fdac727ee6d84d7b2f9a969be5aea2633d848afefc92de89b5ba84f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=0929ea384f8f36d693266473db72d598c11359cd46e79720f7c27017a3771a0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/aa/cc/f2228050ccb40f22144b073f15a2c84f11204f29fc0dce028e\n",
            "Successfully built fake-useragent parse\n",
            "Installing collected packages: websockets, urllib3, pyee, cssselect, w3lib, pyquery, pyppeteer, parse, fake-useragent, requests-html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed cssselect-1.2.0 fake-useragent-0.1.11 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests-html-0.10.0 urllib3-1.25.11 w3lib-2.0.1 websockets-10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from requests_html import HTMLSession"
      ],
      "metadata": {
        "id": "_VbshM90feJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2 Other Parts**"
      ],
      "metadata": {
        "id": "c58p6BYZf-NY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = HTMLSession()\n",
        "r = s.get('https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-3.html')\n",
        "posts = r.html.find('div.Liner', first=True).find('h1')\n",
        "for post in posts:\n",
        "  print(post.text)"
      ],
      "metadata": {
        "id": "Dq6dqImzgBLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.0 Soap and Request**"
      ],
      "metadata": {
        "id": "Wtu9Pi2HnnA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.1 Libraries**"
      ],
      "metadata": {
        "id": "mBmv_hCRnqhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import os"
      ],
      "metadata": {
        "id": "7jOVUaW6nwqI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.2 Other Parts**"
      ],
      "metadata": {
        "id": "uoiNjJC-oDdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://www.advance-africa.com/KCSE-Past-Papers.html\""
      ],
      "metadata": {
        "id": "GWZKG7AKoGo5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page = urllib.request.urlopen(URL)\n",
        "print(page)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5K8A7AzoLLs",
        "outputId": "b2b1b19c-5ff3-4b0e-a428-725de3f9be4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<http.client.HTTPResponse object at 0x7f1697b73590>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kisw = BeautifulSoup(page, \"html.parser\")\n",
        "#print(kisw)\n",
        "#Too heavy"
      ],
      "metadata": {
        "id": "PIu7CNLTox24"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.3 Clean to Get Links Only**"
      ],
      "metadata": {
        "id": "eA_C_aFFqMoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for link in kisw.findAll('a'):\n",
        "  theLink = link.get('href')\n",
        "  name = link.string\n",
        "\n",
        "  print(theLink)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OysxSGeqUe9",
        "outputId": "9b492a76-acbe-4b8c-c753-26b22b918bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.advance-africa.com/KCSE-Past-Papers-Agriculture-2021-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Agriculture-2021-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Biology-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Biology-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Biology-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Business-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Business-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Chemistry-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Chemistry-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Chemistry-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-CRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-CRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-English-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-English-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-English-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Geography-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Geography-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-History-and-Government-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-History-and-Government-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Home-Science-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Home-Science-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Home-Science-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-IRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-IRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Mathematics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Mathematics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Physics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Physics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Physics-Paper-3.html\n",
            "https://iu.prf.hn/click/camref:1101la5KG/creativeref:1101l56937\n",
            "https://www.advance-africa.com/Kapsabet-Mock-Biology-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kapsabet-Mock-Biology-Paper-3-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Agriculture-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Agriculture-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Biology-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Biology-Paper-3-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Biology-Paper-3-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Business-Studies-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Business-Studies-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-English-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-English-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-English-Paper-3-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Chemistry-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Chemistry-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Chemistry-Paper-3-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Computer-Studies-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Computer-Studies-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-CRE-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-CRE-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Geography-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Geography-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-History-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-History-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Home-Science-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Home-Science-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Home-Science-Paper-3-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Kiswahili-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Kiswahili-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Kiswahili-Paper-3-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Mathematics-Paper-1-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/Kenya-High-Mock-Mathematics-Paper-2-2021-With-Marking-Scheme.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Agriculture-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Agriculture-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Biology-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Biology-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Biology-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Business-Studies-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Business-Studies-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Computer-Studies-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Computer-Studies-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Chemistry-paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Chemistry-paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Chemistry-paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-CRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-CRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-English-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-English-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-English-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Geography-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Geography-paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-History-and-Government-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-History-and-Government-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Home-Science-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Home-Science-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Home-Science-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-IRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-IRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Kiswahili-Karatasi-ya-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Kiswahili-Karatasi-ya-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Kiswahili-Karatasi-ya-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Mathematics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Mathematics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Physics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Physics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Physics-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Agriculture-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Agriculture-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Aviation-Technology-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Biology-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Biology-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Biology-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Building-and-Construction-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Business-Studies-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Business-Studies-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Computer-Studies-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Computer-Studies-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Chemistry-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Chemistry-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Chemist-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-CRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-CRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-English-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-English-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-English-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Geography-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Geography-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-History-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-History-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Home-Science-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Home-Science-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Home-Science-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-IRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-IRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Kiswahili-Karatasi-ya-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Kiswahili-Karatasi-ya-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Kiswahili-Karatasi-ya-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Mathematics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Mathematics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Physics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Physics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Physics-Paper-3.html\n",
            "https://www.advance-africa.com/KNEC-KCSE-2019-Power-Mechanics-Paper-1.html\n",
            "https://iu.prf.hn/click/camref:1101la5KG/creativeref:1101l56937\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Agriculture-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Agriculture-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Biology-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Biology-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Biology-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Business-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Business-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Computer-Studies-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Computer-Studies-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Chemistry-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Chemistry-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Chemistry-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-CRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-CRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-English-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-English-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-English-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Geography-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Geography-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-History-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-History-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Home-Science-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Home-Science-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-IRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-IRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Kiswahili-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Kiswahili-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Kiswahili-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Mathematics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Mathematics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Physics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Physics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2018-Physics-Paper-3.html\n",
            "https://iu.prf.hn/click/camref:1101la5KG/creativeref:1101l56937\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Agriculture-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Agriculture-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Art-and-Design-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Art-and-Design-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Aviation-Technology-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Aviation-Technology-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Biology-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Biology-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Biology-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Building-and-Construction-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Business-Studies-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Business-Studies-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Chemistry-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Chemistry-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Chemistry-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Computer-Studies-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Computer-Studies-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Computer-Studies-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-CRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-CRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Drawing-and-Design-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Electricity-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Electricity-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-English-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-English-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-English-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-General-Science-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-General-Science-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Geography-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Geography-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-History-and-Government-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-History-and-Government-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Home-Science-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Home-Science-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Home-Science-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-H-R-E-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-H-R-E-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-I-R-E-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-I-R-E-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Kiswahili-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Kiswahili-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Kiswahili-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Mathematics-Alt-A-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Mathematics-Alt-A-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Mathematics-Alt-B-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Mathematics-Alt-B-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Physics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Physics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Physics-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Power-Mechanics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Power-Mechanics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2017-Woodwork-Paper-1.html\n",
            "https://www.advance-africa.com/How-to-Revise-Efficiently.html\n",
            "https://www.advance-africa.com/inside-the-river-and-the-source-why-literature-students-should-master-set-texts.html\n",
            "https://www.advance-africa.com/the-secret-to-top-exam-marks-is-a-reading-culture.html\n",
            "https://www.advance-africa.com/the-main-characters-and-their-roles-in-betrayal-in-the-city.html\n",
            "https://www.advance-africa.com/styles-and-their-effectiveness-in-imbugas-betrayal-in-the-city.html\n",
            "https://www.advance-africa.com/how-theme-of-betrayal-runs-deep-in-francis-imbugas-book.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Agriculture-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Agriculture-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Biology-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Biology-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Biology-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Business-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Business-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Chemistry-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Chemistry-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Chemistry-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Computer-Studies-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Computer-Studies-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-CRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-CRE-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-English-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-English-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-English-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Geography-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Geography-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-History-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-History-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Kiswahili-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Kiswahili-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Kiswahili-Paper-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Mathematics-Alt-A-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Mathematics-Alt-A-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Physics-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Physics-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2016-Physics-Paper-3.html\n",
            "https://www.advance-africa.com/How-to-Revise-Efficiently.html\n",
            "https://www.advance-africa.com/inside-the-river-and-the-source-why-literature-students-should-master-set-texts.html\n",
            "https://www.advance-africa.com/the-secret-to-top-exam-marks-is-a-reading-culture.html\n",
            "https://www.advance-africa.com/the-main-characters-and-their-roles-in-betrayal-in-the-city.html\n",
            "https://www.advance-africa.com/styles-and-their-effectiveness-in-imbugas-betrayal-in-the-city.html\n",
            "https://www.advance-africa.com/how-theme-of-betrayal-runs-deep-in-francis-imbugas-book.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Agriculture-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Biology-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Business-Studies-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Chemistry-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-CRE-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-English-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-General-Science-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Geography-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-History-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Home-Science-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Kiswahili-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Maths-A-2015.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Physics-2015.html\n",
            "https://www.advance-africa.com/How-to-Revise-Efficiently.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Art-and-Design-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Agriculture-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Aviation-Technology-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Biology-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Building-and-Construction-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Business-Studies-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Chemistry-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Computer-Studies-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-CRE-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Drawing-and-Design-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Electricity-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-English-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-General-Science-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Geography-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-History-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Home-Science-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-HRE-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-IRE-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Kiswahili-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Maths-A-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Maths-B-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Metalwork-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Physics-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Power-Mechanics-2014.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Woodwork-2014.html\n",
            "https://www.advance-africa.com/How-to-Revise-Efficiently.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Art-and-Design-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Agriculture-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Aviation-Technology-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Biology-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Building-and-Construction-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Business-Studies-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Chemistry-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Computer-Studies-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-CRE-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Drawing-and-Design-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Electricity-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-English-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-General-Science-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Geography-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-History-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Home-Science-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-HRE-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-IRE-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Kiswahili-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Maths-A-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Maths-B-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Metalwork-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Physics-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Power-Mechanics-2013.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Woodwork-2013.html\n",
            "https://www.advance-africa.com/How-to-Revise-Efficiently.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Art-and-Design-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Agriculture-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Aviation-Technology-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Biology-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Building-and-Construction-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Business-Studies-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Chemistry-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Computer-Studies-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-CRE-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-General-Science-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Geography-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-History-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Metalwork-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Music-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Physics-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Power-Mechanics-2011.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-Woodwork-2011.html\n",
            "https://www.advance-africa.com/KCSE-Revision-Notes.html\n",
            "https://www.advance-africa.com/How-to-Revise-Efficiently.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2010-Agriculture-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2010-Biology-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2010-Biology-Paper-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2010-CRE-Paper-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2010-CRE-Paper-2.html\n",
            "https://www.advance-africa.com/Agriculture-Notes-1.html\n",
            "https://www.advance-africa.com/How-to-Revise-Efficiently.html\n",
            "https://www.advance-africa.com/Biology-Diagrams.html\n",
            "https://www.advance-africa.com/Biology-Questions-and-Answers-Form-1.html\n",
            "https://www.advance-africa.com/Biology-Questions-and-Answers-Form-2.html\n",
            "https://www.advance-africa.com/Biology-Questions-and-Answers-Form-3.html\n",
            "https://www.advance-africa.com/Biology-Questions-and-Answers-Form-4.html\n",
            "https://www.advance-africa.com/Chemistry-Notes-Acid-Bases-and-Indicators.html\n",
            "https://www.advance-africa.com/Chemistry-Notes-Acid-Bases-and-Salts.html\n",
            "https://www.advance-africa.com/CRE-Notes.html\n",
            "https://www.advance-africa.com/Betrayal-in-the-City.html\n",
            "https://www.advance-africa.com/Biology-Study-Guide.html\n",
            "https://www.advance-africa.com/Business-Studies-Notes.html\n",
            "https://www.advance-africa.com/CRE-Notes.html\n",
            "https://www.advance-africa.com/CRE-Notes-Form-1-4.html\n",
            "#Help\n",
            "#closehelp\n",
            "#here\n",
            "/privacy-policy.html\n",
            "/kcse-marking-schemes.html\n",
            "/kcse-prediction-past-papers-2023-free-downloads.html\n",
            "/inside-the-river-and-the-source-why-literature-students-should-master-set-texts.html\n",
            "/other-themes-in-john-steinbecks-book-the-pearl.html\n",
            "/kenya-daily-newspapers.html\n",
            "/organic-and-nonorganic-milk-and-meat-which-is-more-nutritious.html\n",
            "/organic-milk-meat-richer-in-omega3-study.html\n",
            "#INV\n",
            "https://www.advance-africa.com/KCSE-Results.html\n",
            "https://www.advance-africa.com/KCSE-Results-Top-100-Schools.html\n",
            "https://www.advance-africa.com/KCSE-Top-100-Candidates.html\n",
            "https://www.advance-africa.com/Kenya-Certificate-of-Secondary-Education.html\n",
            "https://www.advance-africa.com/Kenya-National-Examinations-Council.html\n",
            "https://www.advance-africa.com/Secondary-Schools-in-Kenya.html\n",
            "https://www.advance-africa.com/KNEC.html\n",
            "https://www.advance-africa.com/Kenya-Scholarships.html\n",
            "https://www.advance-africa.com/Kenya-Scholarships.html\n",
            "https://www.advance-africa.com/Undergraduate-Scholarships-for-Kenyan-Students.html\n",
            "https://www.advance-africa.com/Kenya-Undergraduate-Scholarships.html\n",
            "https://www.advance-africa.com/Undergraduate-Scholarships.html\n",
            "https://www.advance-africa.com/Kenya-Postgraduate-Scholarships.html\n",
            "https://www.advance-africa.com/Scholarships-and-Grants.html\n",
            "https://www.advance-africa.com/Undergraduate-Scholarships.html\n",
            "https://www.advance-africa.com/Universities-in-Kenya.html\n",
            "https://www.advance-africa.com/Kenya-Universities-and-Colleges-Central-Placement-Service.html\n",
            "https://www.advance-africa.com/Colleges-in-Kenya.html\n",
            "https://www.advance-africa.com/KASNEB.html\n",
            "https://www.advance-africa.com/Scholarships-for-Primary-and-High-School-students.html\n",
            "https://www.advance-africa.com/Scholarships-for-Kenyans.html\n",
            "https://www.advance-africa.com/Motivational-Quotes-for-Students.html\n",
            "https://www.advance-africa.com/Success-Quotes.html\n",
            "https://www.advance-africa.com/Motivational-Quotes-for-Students.html\n",
            "https://www.advance-africa.com/Success-Quotes.html\n",
            "https://www.advance-africa.com/KCSE-Prediction-Questions-and-Answers.html\n",
            "/\n",
            "/contact-infomation.html\n",
            "/Grants-for-NGOs-and-Organisations.html\n",
            "/List-of-Scholarships-for-International-Students.html\n",
            "/Jobs-in-Kenya.html\n",
            "/Jobs-in-Africa.html\n",
            "/About-Us.html\n",
            "/Link-to-Us.html\n",
            "/Site-Search.html\n",
            "/african-scholarships-blog.html\n",
            "/Volunteer-in-Africa.html\n",
            "/Volunteer-in-Kenya.html\n",
            "/Medical-Electives.html\n",
            "/Submit-an-Article.html\n",
            "/internships.html\n",
            "/Scholarships-and-Grants.html\n",
            "/Undergraduate-Scholarships.html\n",
            "/Call-for-Proposals.html\n",
            "/Studying-Abroad.html\n",
            "/Kenya-Universities-and-Colleges-Central-Placement-Service.html\n",
            "/KCSE-Revision-Notes.html\n",
            "/KCSE-Past-Papers.html\n",
            "/Research_Grants.html\n",
            "/Opportunities-for-Entrepreneurs.html\n",
            "/Artist-Grants-and-Opportunities.html\n",
            "/Opportunities-for-Journalists-Worldwide.html\n",
            "https://www.advance-africa.com/Scholarships-and-Grants.html\n",
            "https://www.advance-africa.com/List-of-Scholarships-for-International-Students.html\n",
            "https://www.advance-africa.com/Undergraduate-Scholarships.html\n",
            "https://www.advance-africa.com/Scholarships-and-Grants.html\n",
            "https://www.advance-africa.com/PhD-and-Masters-by-Research-Scholarships.html\n",
            "https://www.advance-africa.com/Opportunities-for-Journalists-Worldwide.html\n",
            "https://www.advance-africa.com/Grants-for-NGOs-and-Organisations.html\n",
            "https://www.advance-africa.com/Artist-Grants-and-Opportunities.html\n",
            "https://www.advance-africa.com/Opportunities-for-Entrepreneurs.html\n",
            "https://iubh.prf.hn/click/camref:1101la5KG/creativeref:1011l54314\n",
            "https://www.advance-africa.com/List-of-Scholarships-for-International-Students.html\n",
            "https://www.advance-africa.com/Jobs-in-Kenya.html\n",
            "https://www.advance-africa.com/Jobs-in-Uganda.html\n",
            "https://www.advance-africa.com/Jobs-in-Ethiopia.html\n",
            "https://www.advance-africa.com/Jobs-in-Nigeria.html\n",
            "https://www.advance-africa.com/Jobs-in-South-Sudan.html\n",
            "https://www.advance-africa.com/Jobs-in-South-Africa.html\n",
            "https://www.advance-africa.com/Jobs-in-Rwanda.html\n",
            "https://www.advance-africa.com/Jobs-in-Zambia.html\n",
            "https://www.advance-africa.com/Jobs-in-Malawi.html\n",
            "https://www.advance-africa.com/Jobs-in-Ghana.html\n",
            "https://www.advance-africa.com/Jobs-in-Tanzania.html\n",
            "https://www.advance-africa.com/Scholarships-and-Grants.html\n",
            "https://www.advance-africa.com/List-of-Scholarships-for-International-Students.html\n",
            "https://www.advance-africa.com/Undergraduate-Scholarships.html\n",
            "https://www.advance-africa.com/Scholarships-and-Grants.html\n",
            "https://www.advance-africa.com/PhD-and-Masters-by-Research-Scholarships.html\n",
            "https://www.advance-africa.com/Opportunities-for-Journalists-Worldwide.html\n",
            "https://www.advance-africa.com/Grants-for-NGOs-and-Organisations.html\n",
            "https://www.advance-africa.com/Artist-Grants-and-Opportunities.html\n",
            "https://www.advance-africa.com/Opportunities-for-Entrepreneurs.html\n",
            "https://iubh.prf.hn/click/camref:1101la5KG/creativeref:1011l54314\n",
            "https://www.advance-africa.com/List-of-Scholarships-for-International-Students.html\n",
            "https://www.advance-africa.com/Jobs-in-Kenya.html\n",
            "https://www.advance-africa.com/Jobs-in-Uganda.html\n",
            "https://www.advance-africa.com/Jobs-in-Ethiopia.html\n",
            "https://www.advance-africa.com/Jobs-in-Nigeria.html\n",
            "https://www.advance-africa.com/Jobs-in-South-Sudan.html\n",
            "https://www.advance-africa.com/Jobs-in-South-Africa.html\n",
            "https://www.advance-africa.com/Jobs-in-Rwanda.html\n",
            "https://www.advance-africa.com/Jobs-in-Zambia.html\n",
            "https://www.advance-africa.com/Jobs-in-Malawi.html\n",
            "https://www.advance-africa.com/Jobs-in-Ghana.html\n",
            "https://www.advance-africa.com/Jobs-in-Tanzania.html\n",
            "https://www.advance-africa.com/Scholarships-and-Grants.html\n",
            "https://www.advance-africa.com/List-of-Scholarships-for-International-Students.html\n",
            "https://www.advance-africa.com/Undergraduate-Scholarships.html\n",
            "https://www.advance-africa.com/Scholarships-and-Grants.html\n",
            "https://www.advance-africa.com/PhD-and-Masters-by-Research-Scholarships.html\n",
            "https://www.advance-africa.com/Opportunities-for-Journalists-Worldwide.html\n",
            "https://www.advance-africa.com/Grants-for-NGOs-and-Organisations.html\n",
            "https://www.advance-africa.com/Artist-Grants-and-Opportunities.html\n",
            "https://www.advance-africa.com/Opportunities-for-Entrepreneurs.html\n",
            "https://iubh.prf.hn/click/camref:1101la5KG/creativeref:1011l54314\n",
            "https://www.advance-africa.com/List-of-Scholarships-for-International-Students.html\n",
            "https://www.advance-africa.com/Jobs-in-Kenya.html\n",
            "https://www.advance-africa.com/Jobs-in-Uganda.html\n",
            "https://www.advance-africa.com/Jobs-in-Ethiopia.html\n",
            "https://www.advance-africa.com/Jobs-in-Nigeria.html\n",
            "https://www.advance-africa.com/Jobs-in-South-Sudan.html\n",
            "https://www.advance-africa.com/Jobs-in-South-Africa.html\n",
            "https://www.advance-africa.com/Jobs-in-Rwanda.html\n",
            "https://www.advance-africa.com/Jobs-in-Zambia.html\n",
            "https://www.advance-africa.com/Jobs-in-Malawi.html\n",
            "https://www.advance-africa.com/Jobs-in-Ghana.html\n",
            "https://www.advance-africa.com/Jobs-in-Tanzania.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.4 Filtering to Get Kiswahili Papers**"
      ],
      "metadata": {
        "id": "xwmNmcFNqRdK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   We shall use splicing\n",
        "*   Where we shall match the elements on the wesbite i.e. theLink[-18:]== \"Karatasi-ya-1.html\"\n",
        "\n"
      ],
      "metadata": {
        "id": "9vxK9jQwrk3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for link in kisw.findAll('a'):\n",
        "  theLink = link.get('href')\n",
        "  name = link.string\n",
        "\n",
        "  if theLink[-18:] == \"Karatasi-ya-1.html\" or theLink[-18:] == \"Karatasi-ya-2.html\" or theLink[-18:] == \"Karatasi-ya-3.html\":\n",
        "    print(theLink)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koNZ5P0urn9D",
        "outputId": "ba189f5a-60cb-4cdf-8e6b-ab4b3132eaab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Kiswahili-Karatasi-ya-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Kiswahili-Karatasi-ya-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2020-Kiswahili-Karatasi-ya-3.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Kiswahili-Karatasi-ya-1.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Kiswahili-Karatasi-ya-2.html\n",
            "https://www.advance-africa.com/KCSE-Past-Papers-2019-Kiswahili-Karatasi-ya-3.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.5 Printing and Saving the Contents**"
      ],
      "metadata": {
        "id": "YdLGO0vRtY4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.5.0 This Will Work for .Doc and .Pdf**"
      ],
      "metadata": {
        "id": "N7MRxvzAxA-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for link in kisw.findAll('a'):\n",
        "  theLink = link.get('href')\n",
        "  name = link.string\n",
        "\n",
        "  if theLink[-18:] == \"Karatasi-ya-1.html\":\n",
        "    if theLink[-18:] == \"Karatasi-ya-1.html\":\n",
        "      fileExtension = \"Karatasi-ya-1.html\"\n",
        "      if name is None:\n",
        "        title = \"Title is None\" + fileExtension\n",
        "      else:\n",
        "          title = name + fileExtension\n",
        "      try:\n",
        "          with open(os.getcwd() + \"/documents/\" + title, \"r\") as fileExists:\n",
        "            print(title + \"exists\")\n",
        "            fileExists.close()\n",
        "      except FileNotFoundError:\n",
        "          print(\"Download Started:\" + title)\n",
        "          docFile = open(os.getcwd() + \"/documents/\" + title, \"wb\")\n",
        "          docFile.write(urllib.request.urlopen(theLink).read())\n",
        "          docFile.close()\n",
        "          print(\"Success\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "Xm3xvecZtc_p",
        "outputId": "b91adf3f-0e04-4b65-894c-fc70c44f6996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download Started:Title is NoneKaratasi-ya-1.html\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-bb4fd0a41cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m           \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/documents/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfileExists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/documents/Title is NoneKaratasi-ya-1.html'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-bb4fd0a41cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Download Started:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0mdocFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/documents/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0mdocFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheLink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0mdocFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/documents/Title is NoneKaratasi-ya-1.html'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.0 G 4 G BS4 and Urllib**"
      ],
      "metadata": {
        "id": "ZOJx4I4yCcXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8.1 Libraries**"
      ],
      "metadata": {
        "id": "FAQOStsrChPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xHQWn5-Cspf",
        "outputId": "dbfe9612-a01b-45b0-dfb5-215409ceed7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install urllib3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgxtMXqnCzFF",
        "outputId": "629d57d5-e45e-42c4-f593-488ade517282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8.2 Other Parts**"
      ],
      "metadata": {
        "id": "ReDkQJ18DB5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# here we have to pass url and path\n",
        "# (where you want to save ur text file)\n",
        "urllib.request.urlretrieve(\"https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-1.html\",\n",
        "\t\t\t\t\t\t\"/content/kiswahili data/kisw.txt\")\n",
        "\n",
        "file = open(\"/content/kiswahili data/kisw.txt\", \"r\")\n",
        "contents = file.read()\n",
        "soup = BeautifulSoup(contents, 'html.parser')\n",
        "\n",
        "f = open(\"test1.txt\", \"w\")\n",
        "\n",
        "# traverse paragraphs from soup\n",
        "for data in soup.find_all(\"p\"):\n",
        "\tsum = data.get_text()\n",
        "\tf.writelines(sum)\n",
        "\n",
        "f.close()\n"
      ],
      "metadata": {
        "id": "f_SunmZ9DEf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   This one gets the entire html website and copies it into the text file\n",
        "*   What we do next is specify the exact location of our text data and write that to our destination file (txt or csv).\n",
        "\n"
      ],
      "metadata": {
        "id": "k8R-JCTlHHga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.0 Refined Scraper**"
      ],
      "metadata": {
        "id": "iiHSB56EHW06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.1 Libraries**"
      ],
      "metadata": {
        "id": "i2q_KUOoHbZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ63lc6pHd6j",
        "outputId": "3064f1df-a3e7-4be5-969e-1b9ab87c7545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.2 Inspect our SOurce**"
      ],
      "metadata": {
        "id": "-QI8rAAtNZka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Opened the html website. \n",
        "*   Inspected the site to locate area I want to scrape my data.\n",
        "\n"
      ],
      "metadata": {
        "id": "LJtucERMN-4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.3 Getting the HTML Content**"
      ],
      "metadata": {
        "id": "IKn7_YoPOIcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import requests library\n",
        "import requests\n",
        "#the website URL\n",
        "url_link = \"https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-2.html\"\n",
        "#result = requests.get(url_link).text\n",
        "#print(result)\n",
        "\n",
        "#Output is too heavy"
      ],
      "metadata": {
        "id": "EQTtAvY0ONSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.4 Parsing an HTML Page with Beautiful Soup**"
      ],
      "metadata": {
        "id": "FF1ifHAgPYDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "#import requests library\n",
        "import requests\n",
        "#the website URL\n",
        "url_link = \"https://www.advance-africa.com/KCSE-Past-Papers-2021-Kiswahili-Karatasi-ya-2.html\"\n",
        "#result = requests.get(url_link).text\n",
        "#doc = BeautifulSoup(result, \"html.parser\")\n",
        "\n",
        "#print(doc.prettify())\n",
        "#Output is too heavy"
      ],
      "metadata": {
        "id": "FXhg3o3iNdni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.5 Finding Elements**"
      ],
      "metadata": {
        "id": "Z28IUceLPr75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By ID**"
      ],
      "metadata": {
        "id": "XZyjSs_9P25c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = doc.find(id = \"ContentColumn\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7PRsQj6P5rD",
        "outputId": "b1d244ad-7941-4e73-bba7-79257d3437aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<div id=\"ContentColumn\">\n",
            "<div class=\"Liner\">\n",
            "<!-- start: shared_blocks.101250255#above-h1 -->\n",
            "<div class=\"\" style=\"width: 100%; box-sizing: border-box\"></div>\n",
            "<!-- end: shared_blocks.101250255#above-h1 -->\n",
            "<h1>KCSE Past Papers 2021 Kiswahili Karatasi ya 2 (102/2)<br/></h1>\n",
            "<!-- start: shared_blocks.103089388#1st Ad -->\n",
            "<table align=\"center\" width=\"100\"> <tr> <td>\n",
            "<script async=\"\" src=\"//pagead2.googlesyndication.com/pagead/j3/adsbygoogle.js\"></script>\n",
            "<!-- Crazy -->\n",
            "<ins class=\"adsbygoogle\" data-ad-client=\"ca-pub-0326674550430411\" data-ad-slot=\"5740034820\" data-full-width-responsive=\"true\" style=\"display:inline-block;width:336px;height:280px\"></ins>\n",
            "<script>(adsbygoogle=window.adsbygoogle||[]).push({});</script> </td></tr></table>\n",
            "<!-- end: shared_blocks.103089388#1st Ad -->\n",
            "<a href=\"https://www.advance-africa.com/KCSE-Past-Papers.html\" target=\"_blank\"> <center> <h3> <font color=\"#000066\"> Click Here - Free KCSE Past Papers » KNEC Past Exams » Free Downloads » KCSE Papers &amp; Marking Schemes </font></h3></center></a> </div></div>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By Class**"
      ],
      "metadata": {
        "id": "6mwD3TLvQNyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heading = res.find(class_ = \"Liner\")\n",
        "print(heading)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D1DMDdjQP3s",
        "outputId": "3080d186-1eca-4b3a-e1dc-e5e1dc4e4e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<div class=\"Liner\">\n",
            "<!-- start: shared_blocks.101250255#above-h1 -->\n",
            "<div class=\"\" style=\"width: 100%; box-sizing: border-box\"></div>\n",
            "<!-- end: shared_blocks.101250255#above-h1 -->\n",
            "<h1>KCSE Past Papers 2021 Kiswahili Karatasi ya 2 (102/2)<br/></h1>\n",
            "<!-- start: shared_blocks.103089388#1st Ad -->\n",
            "<table align=\"center\" width=\"100\"> <tr> <td>\n",
            "<script async=\"\" src=\"//pagead2.googlesyndication.com/pagead/j3/adsbygoogle.js\"></script>\n",
            "<!-- Crazy -->\n",
            "<ins class=\"adsbygoogle\" data-ad-client=\"ca-pub-0326674550430411\" data-ad-slot=\"5740034820\" data-full-width-responsive=\"true\" style=\"display:inline-block;width:336px;height:280px\"></ins>\n",
            "<script>(adsbygoogle=window.adsbygoogle||[]).push({});</script> </td></tr></table>\n",
            "<!-- end: shared_blocks.103089388#1st Ad -->\n",
            "<a href=\"https://www.advance-africa.com/KCSE-Past-Papers.html\" target=\"_blank\"> <center> <h3> <font color=\"#000066\"> Click Here - Free KCSE Past Papers » KNEC Past Exams » Free Downloads » KCSE Papers &amp; Marking Schemes </font></h3></center></a> </div>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heading = res.find(class_ = \"Liner\")\n",
        "print(heading.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7exdc8d7Qjug",
        "outputId": "3fd0037b-1a55-4c2b-f115-eb6a62e7c888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "KCSE Past Papers 2021 Kiswahili Karatasi ya 2 (102/2)\n",
            "\n",
            "  \n",
            "\n",
            "\n",
            "\n",
            "(adsbygoogle=window.adsbygoogle||[]).push({}); \n",
            "\n",
            "    Click Here - Free KCSE Past Papers » KNEC Past Exams » Free Downloads » KCSE Papers & Marking Schemes  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9.6 Getting our data using the available tags**"
      ],
      "metadata": {
        "id": "auP8ZFPeRmRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_data=doc.find(“table”, class_=“liner”)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "DJTO7QQgTVH_",
        "outputId": "92e6896a-bd1a-45c8-cf67-f89c624245b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-6dc057cae654>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    my_data=doc.find(“table”, class_=“liner”)\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "div_tags = my_data.find_all('div')\n",
        "names = []\n",
        "for elem in div_tags:\n",
        "  #finding the < a > tag\n",
        "a_links = elem.find_all(\"a\")\n",
        "#getting the text inside the < a > tag\n",
        "for i in a_links:\n",
        "  names.append(i.string)\n",
        "print(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "AMcfX2PERsVs",
        "outputId": "d257d5ae-5b6b-4fc0-cc89-e960fcf5fed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-16beb11a29c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiv_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiv_tags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#finding the < a > tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0ma_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'my_table' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reason I have been having a hard time is because of how Kenyan/Kiswahili Websites are designed!!! BAD WORK**"
      ],
      "metadata": {
        "id": "2YzksAQfg9Ci"
      }
    }
  ]
}