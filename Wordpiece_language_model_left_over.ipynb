{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZKlC9cka7n/RjbLSLFa28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdkdaniel/The-Swahili-Project/blob/main/Wordpiece_language_model_left_over.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY-sNETSqKyN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s-Y-UEEBqNuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Language Model**"
      ],
      "metadata": {
        "id": "Fivd08NG0Mky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast"
      ],
      "metadata": {
        "id": "veL1wik00QFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = '/content/drive/MyDrive/Kiswahili_Project/The_Tokenizers/Kisw_wordpiece_tokn'\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "aDVhiD6n0jjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding"
      ],
      "metadata": {
        "id": "bJ_ClnKK0kMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "79cb16eb5b084d32ad68d36638e0ddce",
            "d7cb91cead834fe5b82833ff8d926b5b",
            "e94e2fe353464abba77d781a990570d4",
            "099dffb1e47141f3b49e8ad618848538",
            "d5af7d3b8d444efb9a545afaa68176b1",
            "63c7f585148840c3bdc5a83cb20d4455",
            "6b242ad14f064312a9dfce0d3d8eb921",
            "b36c586f7cc34813b57eef7fe108b1d5",
            "6e1a5a65be2547529f9eab9e12a38234",
            "99e4cf53da814db38f96f4ae2ddb9f9d",
            "bef17c8ac05b4cdfada40088927d03db",
            "4ea3de54ada549b0a072c74728654127",
            "a70a009852af4439bc1f19b6ec1d7d44",
            "52580c8294034cb0acc188ccd22f7b6d",
            "41ab697bd88746b59d5b271f54cb0057",
            "aeae580920e14c85a9ee0f8941b39162",
            "b5ca87b7638d4b2cb14bd5d6f00942a2",
            "00626e50879947ec9f105d710b9a0b42",
            "db63cc0a9fc743be9cb1ca4ffcfb9ed6",
            "9a57deb1411b431d905a3c891557b085",
            "c62b4edd239f40659a239835660db9f7",
            "ae95304e6e814897ba1b40aa6adbb05c",
            "1d82702890124ee5bcf8e975269c2210",
            "d341787a372a4def86d084041ddaba4d",
            "294899dcc405405592038d517300ac4d",
            "6eb8924653ec45ff9b54459f23c529cc",
            "b63f2f23eeb3423e804c6d21fa036021",
            "33dfc29fbf5b498787ceccab27ff80bc",
            "5ad5150bb81b42e3903bbefbab3587c2",
            "c85fe35205824d33b81293158e63faa8",
            "07c55cdd66fe4e17940b686bbe53de05",
            "dd576ca70bb3432b8d732713f777fe3b",
            "3956722c8c784d93a215a96408225b53",
            "b6e2e84d71d44402bb05b6008bf02637",
            "d2030f42b73d471ea627246209f2e79c",
            "2d0bbe2ff793440e94247d13cd0eabfd",
            "a05f2963dc1a45d1817a3f6b02a04f23",
            "53fc3aa578a84a97a902fd7064331ac1",
            "57b4e8c439174fec9da69f6bed527e59",
            "11e411c7dc5e44f980111df5c532862c",
            "ea03960ded744af6b00b3b3e4aea5de8",
            "3f687f37e720492a99431ff14b58902f",
            "3f8ec5e404b34937893802a6eb981a16",
            "d0af6f7d48b546d698a8f4b330f90475"
          ]
        },
        "id": "H9Uxcn7k0uaf",
        "outputId": "9728281a-23b1-4cc7-89e1-93ddf5f8f8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79cb16eb5b084d32ad68d36638e0ddce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ea3de54ada549b0a072c74728654127"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d82702890124ee5bcf8e975269c2210"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6e2e84d71d44402bb05b6008bf02637"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"swahili\")\n",
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515,
          "referenced_widgets": [
            "6d81ea3cf723401f8ecc396a4ab7967f",
            "64629bf27aae4b3a81d769e2603c12ef",
            "b34dd4aa90b54b00b4eb24c25836fef2",
            "b3712cbbc52047cd96fd62e45ce6ca54",
            "6d759d3a02df402f8a35bfa46db3f387",
            "0bd5ccc9b3dd40b3bb677e0473895d16",
            "da4c7b39c0d34df4b321ff05638ddcab",
            "8d09ea8e22b44eb4b64f3973e8d53195",
            "b1685ef123df4530833ee0be2162e0f9",
            "5cc98defb4f54182894e9e0db54855c4",
            "36a36679441d4f1cb34c3eaab5ae54e3",
            "57893b3f3efd4715ad8db07924d3313d",
            "efc4a8ee9dfc44abaa75cc7310177d83",
            "1c8e3d9539ed4bf38a903f5b429e7932",
            "88866788ecbb45c1ac60e157bb35f89c",
            "692ccdf1d3744b91b1b1117e8406fc96",
            "cf13d8dc138b43b79129d74007c56168",
            "a77f0bfb96f745769ae5fc77de2a31e6",
            "49a2de6e788c4a15b7ea03a41db89ec7",
            "5ce5ef9bd87a43b0a48702bd2ce5a121",
            "77f4ec3683d242bfbd16837812b081fc",
            "eb20d2e04d7f433ea9dccc47d1023593",
            "018ea058f7e644db8013076f2c08091c",
            "3b4eaa27d8bf4175971777368b288aa6",
            "f33b36e1913c442ebfa49a8384d2a629",
            "0d0123cb374b44fa9e55787dcc87fb76",
            "a6a220cec73643468874bd79757e2d9a",
            "ebcda6a185f849d1a8bec4eda326a9a4",
            "4a69b1cdbaef44838621384a9a81a162",
            "c6253df848094f2cb23c3c755062da7e",
            "60949ac3d8cc4354be67993b16ce3786",
            "6ca9d4cfc639454ea173277fc3cebe92",
            "93d075788c84486195628f35c848bd98",
            "0a272daf68d642aa84eb444668ebf2ba",
            "8778644d732b4468b4ad905ddc24a862",
            "6f87fa266bd5419b8120ff5c3fa280a2",
            "41d6dc32550d4d33b1cc455fa58a27cc",
            "be8cdb7cb2a9482189e75cb9f8264360",
            "45489766e3234f868c75661492d64ee9",
            "a7223d6e10b54152a50eb4822b2a5bab",
            "7b86e558435748d3a7edac1b27e5bcfb",
            "9025e023352b40f0910c30b822b547c2",
            "19a74e2409dc44a686c2e3a8da5b04bf",
            "564b155501724f8c90624992f9fe236f",
            "e0682830c3f5432888630b2744ce0de0",
            "12a48a167e8b4c82aa6efd6673eae835",
            "507c187778a244cb8aaef96f4dde6804",
            "7af0b4a0e80b4a8da5552bf3f879b09d",
            "a7016e00bd314040b5a81e2244368338",
            "aa891d8271144c83ad999eef3d2a0fbd",
            "d294ba15b6094b73a3a002fd8eed5059",
            "4e1a8a2bb50e49dcb4eb9849ac75cbf7",
            "4c213c801d214a0aad1909f52774b98d",
            "13accbc66b2e46cc9a2edd770bbd7cc1",
            "a2aae51078b84839a654b5bb4c0dc083",
            "6667f6ae4f9d4f4597b703bd8f123247",
            "cb37c02763ba4d8a90999d8df7094c67",
            "05d8acfcc48247568b5735623291aca3",
            "3fddfc97ebdc4e0db9639f0b8dd1c02c",
            "ded8627dca184ebba19398faa9e1644c",
            "9ecc6ee1d91e44f491f312037837244b",
            "4c42c3a9444f4b10af62fb3015971cdc",
            "0f989f2def7b4577bf151991f2355dff",
            "37c90608c43d498c9e94f857b9a0f4a3",
            "2078a920dd2a4b5f93827a1644841407",
            "5b5aaaf128a64d6eaada211d72a6fbb1",
            "2ed9a6cbbee2467a98e3a02b6723a632",
            "d184a0aaade64377b606772f8d9b8272",
            "bd32783c25334646a7057317a2c9e24b",
            "17c8770b37e44a74a6046ef5a7ef6e3b",
            "275ef72d1d4b488bb4bbfac8fd3e7252",
            "489cc242fcfe4dc29f17bf1876aeb995",
            "bc1291bfde3e4489a94abe1c38593fe0",
            "2faf9f8539b443f1b36dc8757c9fcbfe",
            "4797e2b2ad074bac8852f50782cee04b",
            "65239216344245429491b6713cc787bc",
            "c655906bb3614973aac53977d56847d0",
            "2e05f8a816d6442bad57c3d3de130fe7",
            "0d01592d5ffb4e9eb61d19378278b5b7",
            "f8b8ccd0bf19414e87dc2ad77fac80ed",
            "8e5ce43dbcba4bf19232bdbb5fbf07cd",
            "46dadfa6ee2c4f4c9263097a0f949924",
            "2581ddf6130a44038efcd241cef56c07",
            "5c6385ff07854b83af710d441259bfd5",
            "ab78abf35df74cff89f157ea96c8cba9",
            "d79ec5e959174e9bab21d54cba0d5d91",
            "a832d099b3fd4543911dbc0f9b72efaa",
            "04bb9474e1674801af8049a0ee9adfe6"
          ]
        },
        "id": "uwZExqkF02tl",
        "outputId": "5c758fe8-7243-49e7-92d8-9b37db42f27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/3.82k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d81ea3cf723401f8ecc396a4ab7967f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.67k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57893b3f3efd4715ad8db07924d3313d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "018ea058f7e644db8013076f2c08091c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset swahili/swahili to /root/.cache/huggingface/datasets/swahili/swahili/1.0.0/15bf1d99abb939f83b5da3c798ed55e9803b3ea430f06bf7e003bd073b60172a...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a272daf68d642aa84eb444668ebf2ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/42069 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0682830c3f5432888630b2744ce0de0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/3371 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6667f6ae4f9d4f4597b703bd8f123247"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3372 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ed9a6cbbee2467a98e3a02b6723a632"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset swahili downloaded and prepared to /root/.cache/huggingface/datasets/swahili/swahili/1.0.0/15bf1d99abb939f83b5da3c798ed55e9803b3ea430f06bf7e003bd073b60172a. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e05f8a816d6442bad57c3d3de130fe7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 42069\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 3371\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 3372\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset = raw_datasets[\"train\"]\n",
        "raw_train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM6hqhja1xJb",
        "outputId": "57056e12-87fc-463c-d6f1-1fb637402853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'taarifa hiyo ilisema kuwa ongezeko la joto la maji juu ya wastani katikati ya bahari ya UNK inaashiria kuwepo kwa mvua za el nino UNK hadi mwishoni mwa april ishirini moja sifuri imeelezwa kuwa ongezeko la joto magharibi mwa bahari ya hindi linatarajiwa kuhamia katikati ya bahari hiyo hali ambayo itasababisha pepo kutoka kaskazini mashariki kuvuma kuelekea bahari ya hindi'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_dataset.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjT2quvm10ZB",
        "outputId": "d27dfb8e-6f57-469d-9625-c51ce134d189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('/content/drive/MyDrive/Kiswahili_Project/The_Tokenizers/Kisw_wordpiece_tokn')\n",
        "\n",
        "tokenized_sentences = tokenizer(raw_datasets[\"train\"][\"text\"])"
      ],
      "metadata": {
        "id": "zQbzNZqC12sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenizer(\n",
        "    raw_datasets[\"train\"][\"text\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuG4T8rX2GQN",
        "outputId": "8b4e52ac-9aff-46e0-f43d-2dd9fa8c1846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "4ihStZ6r2In6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363,
          "referenced_widgets": [
            "271726daad6b4502a79f23981458f546",
            "6ea82bd4d2554498b948202aeabbc3db",
            "465fe0c9077f4ca6b628e19a6613bbe4",
            "4cbe10dc75164b56aa0af07d63f934aa",
            "13e241dfc4fa4547b5aba22ea3ca037b",
            "8dbd16af0ecf49769b83c7e1c87e1cff",
            "5b70e527b9ad4393bd61dcb6e6983563",
            "fb9f1475a8f1460384aeffd6d79ecee4",
            "a845b764c01f46438b2d4e75b5c21091",
            "77352c38121a4cd1ad0c5945b0fc528d",
            "6e224c00f1c246cd8fe24fbc92dbd54c",
            "50f517e9b73a4d0ea53e1249532a7ebc",
            "d526e76836d24dbb99879d161285227f",
            "be0804ac3bd74b4caa2de64fcf82438f",
            "0e128952a43e48718e3c9a2a30889799",
            "7758fdae110c4320addd68d9a916adc0",
            "fe9904f850c6427da91c7709e27d4846",
            "c52f06ef7007437b916f59e376d571b9",
            "688e83ab662940f59aca93058d287c68",
            "b823676898a74e4d989c063e88a3ad15",
            "4f0098fd46cc475ab59944a3fd7f6b91",
            "432a2cb762ab4b50a414110339445ed3",
            "ffc984c63a4f41bbbc301ca4a3796803",
            "6e8b0bef589b4f1c85b201a8d2235a85",
            "86e145bba269483299659ef1e24bc05e",
            "333ad9ff43dc48fc9d6975987132afd5",
            "9d12ee511bef4267a017dfa361bd4807",
            "2d93a579b4e14c9ab686bb45f00b3e99",
            "68c358ccfce44294a9474a6ab7adef00",
            "3a51b54a3a214d3abb8d74c88b36a712",
            "83c13534cfe94e5e833bae3940b8f517",
            "42766d228d0d4789aef24c9c6e695332",
            "8e748d5cddcf4de5891537b3042bc50c"
          ]
        },
        "id": "8M5PLXGS3hWg",
        "outputId": "466bd256-2ce4-49b1-ad9d-bb09e4d8fc68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/43 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "271726daad6b4502a79f23981458f546"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50f517e9b73a4d0ea53e1249532a7ebc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffc984c63a4f41bbbc301ca4a3796803"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 42069\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 3371\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 3372\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "MAwHxQ-Q3oYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = tokenized_datasets[\"train\"][:8]\n",
        "samples = {k: v for k, v in samples.items() if k not in [\"idx\", \"text\"]}\n",
        "[len(x) for x in samples[\"input_ids\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3cacMXw3po5",
        "outputId": "57a08731-33da-4b3e-82e4-fbea0374ea6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[65, 33, 27, 37, 17, 44, 27, 30]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = data_collator(samples)\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unoqxLxu3tZl",
        "outputId": "acf5821a-6467-4a98-ca19-79945bb33e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': torch.Size([8, 65]),\n",
              " 'token_type_ids': torch.Size([8, 65]),\n",
              " 'attention_mask': torch.Size([8, 65])}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "qf3l9JXW32xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\"test-trainer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs35tERw3yp0",
        "outputId": "27f4ac54-3296-43da-f3e7-b9d0661ffbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEJ6q4b139vV",
        "outputId": "f76bb226-c4b7-4e32-cc5b-5f1d241de391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "Zzd8QAFf4IfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "vsPHYH-Q4Jig",
        "outputId": "738a2823-5d01-4cda-b1cc-dd3d0fc8f7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 42069\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 15777\n",
            "  Number of trainable parameters = 109483778\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2582\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                     \u001b[0;34m\"The model did not return a loss from the inputs, only the following keys: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m                     \u001b[0;34mf\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask."
          ]
        }
      ]
    }
  ]
}